{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic HyperParameters Optimization (SHPsO) with Random Search for Hydrological Prediction using LSTMs\n",
    "\n",
    "This code is for paper: \"Ensemble Learning of Catchment-Wise Optimized LSTMs Enhances Regional Rainfall-Runoff modelling - Case Study: Basque Country, Spain\" by Hosseini et al. 2024 (Preprint - under review)\n",
    "\n",
    "# Overview\n",
    "\n",
    "        This code outlines a systematic hyperparameter tuning approach using random search and the proposed approach for ensemble learning of optimized LSTMs in regional hydrology, specifically tailored for hydrological prediction using LSTMs. While the example focuses on Multi-Timescale LSTM (MTS-LSTM), the methodology can be adapted for other Deep Learning models.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Hyperparameter Space Definition ()\n",
    "        \n",
    "        Description: Define the hyperparameters, specifying their ranges and values for simultaneous tuning.\n",
    "        Details: In this study, 10 hyperparameters with two schedules for learning rate were chosen for tuning, as detailed in the associated paper.\n",
    "\n",
    "2. Random Search Training and validation\n",
    "\n",
    "        Description: Execute random searches within the predefined hyperparameter space.\n",
    "        Details:\n",
    "        Initial Configuration: 1000 randomly tuned configurations.\n",
    "\n",
    "        Steps 1 and 2 are the same as a previous paper:\n",
    "        Hosseini Hossein Abadi, Farzad and Prieto Sierra, Cristina and Álvarez Díaz, Cesar, \"Precise Tuning of Regional Hydrological Lstm Networks: Simultaneous Systematic Random Search Optimization.\"\n",
    "        Available at SSRN: https://ssrn.com/abstract=4815562 or http://dx.doi.org/10.2139/ssrn.4815562 (Under Review)\n",
    "        The codes and dataset utilized in that study, along with comprehensive instructions for replicating the experiments, are accessible on our repositories on https://github.com/farzadhoseini/Precise_Tuning_of_Regional_Hydrological_LSTM_Networks and https://doi.org/10.5281/zenodo.11092080.\n",
    "\n",
    "        All the steps for designing the hyperparameter space and performing 1000 random searches are the same and from the mentioned paper.\n",
    "        Here in this new paper, we continue with new steps post-random search. We chose three different ensemble configurations as the following steps present and compare the outcomes after retraining with the best network from the preious paper (ERO network) as the benchmarck.\n",
    "\n",
    "3. Analysis of validation Metrics (Post-random search validation DATASET)\n",
    "\n",
    "        Description: Analyze the results to identify optimal hyperparameter configurations.\n",
    "        Details:\n",
    "        Post-Random Sraech validation DATASET Structure:\n",
    "        Configurations: 1000 (594 successful) lines\n",
    "        Basins: Every configuration results in 25 distinct NSE and KGE metrics for 25 basins with validation data; later we tested final hyper-tuned models' performance on all 40 basins.\n",
    "        Metrics: KGE and NSE values for each basin\n",
    "        Analysis Approach:\n",
    "        Regional Analysis: Averaging metrics across all basins for each configuration for ERO network\n",
    "        Catchment-scale Analysis: Evaluating each basin individually for Catchment-wise Configs ensemble\n",
    "        Top 10 Configs Analysis: Averaging metrics across all basins for each configuration to find the top 10 Configs ensemble (ERO was the first)\n",
    "        K-means Clustering Analysis: Evaluating each basin individually by K-means clustering to find the best Configs ensembles\n",
    "\n",
    "        We explored different ensemble learning approaches for selecting configurations rather than relying solely on the regionally best-performing configuration (ERO network). Ultimately, we adopted 3 approaches for this purpose:\n",
    "        1 - Top 10 Configs: We selected the top ten regionally best-performing configurations on the validation set after 1000 random searches; this ensemble included ERO.\n",
    "        2 - Catchment-wise Configs: Recognizing the uniqueness of the catchments in shaping their hydrological behaviors, we chose the best-performing regional configurations for each catchment individually, regarding its validation metrics. Since validation data was available for only 25 basins, this approach yielded 23 unique configurations, with some overlap in certain cases at the end.\n",
    "        3 - K-means Configs: To minimize cognitive bias in the configuration selection process, we employed a K-means Clustering unsupervised machine learning model. This model was trained on the normalized post-random search validation DATASET to select an ensemble of best-performing regional configurations. After experimenting with different numbers of clusters, we converged on 8 configurations chosen by the K-means Clustering model, representing a cluster with the highest overall average metrics in several tries.\n",
    "\n",
    "        Outcome: The best-performing configuration was selected based on the highest average NSE and KGE metrics across all 25 basins after both 100 and 1000 random searches.\n",
    "\n",
    "4. Training the three ensemble learning methods and benchmarking against ERO\n",
    "\n",
    "        Description: Train the final models identified post-random search optimized configurations.\n",
    "        Training Runs: Conduct 10 training runs using 10 different random seeds for each selected configuration.\n",
    "        Generate ensembles' final predictions (medians of predictions by all configurations in every ensemble on every time step on each random seed)\n",
    "        Outcome: Each method produces an ensemble of 10 predictions, accompanied by their respective metrics for each catchment. This way we could compare the four different approaches.\n",
    "        Comparisons: we plotted box plots in all basins and also CDFs of the metrics and we performed statistical tests to make sure if predictions by different methods are significantly different.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================== Import required libraries ===================\n",
    "\"\"\"\n",
    "import csv\n",
    "import ast\n",
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import shutil\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\~\\neuralhydrology') # In case of using VSC, this can help to activate and run libraries installed\n",
    "# In our experiments we employed NeuralHydrology Python Library (Kratzert et al., (2022). NeuralHydrology --- A Python library for Deep Learning research in hydrology. \n",
    "# Journal of Open Source Software, 7(71), 4050, https://doi.org/10.21105/joss.04050)\n",
    "\n",
    "from neuralhydrology.nh_run import start_run, Config\n",
    "from neuralhydrology.evaluation import metrics, get_tester\n",
    "from neuralhydrology.nh_run_scheduler import schedule_runs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search Setup\n",
    "\n",
    "    Ensuring the randomness and uniformity of the random search algorithm is crucial for effective hyperparameter tuning. Here's how we addressed this in our approach:\n",
    "\n",
    "# Parameter Grid Design\n",
    "\n",
    "    Objective: Cover the entire range of values within the hyperparameter space.\n",
    "    Implementation:\n",
    "    We designed a diverse grid for each hyperparameter based on consultations and initial trial and error.\n",
    "    Recommendation: Before applying this approach to a new dataset, researchers are advised to conduct manual trials on select basins to determine an appropriate hyperparameter space for their regional model.\n",
    "\n",
    "# Random Sampling Mechanism\n",
    "\n",
    "    Objective: Achieve uniform sampling across the hyperparameter space.\n",
    "    Implementation:\n",
    "    We utilized ParameterSampler from scikit-learn's model_selection module.\n",
    "    This mechanism ensures each hyperparameter combination is selected with equal probability, maintaining randomness and uniformity.\n",
    "\n",
    "# Number of Samples\n",
    "    \n",
    "    Objective: Generate sufficient samples to explore the hyperparameter space adequately.\n",
    "    Implementation:\n",
    "    We set the number of samples to n_samples = 1000, considering the size and complexity of the hyperparameter grid.\n",
    "\n",
    "# Independent Sampling\n",
    "\n",
    "    Objective: Ensure each hyperparameter combination is sampled independently.\n",
    "    Implementation:\n",
    "    ParameterSampler was employed to sample each hyperparameter independently, preserving the randomness and uniformity of the sampling process.\n",
    "\n",
    "## Code for Generating Random Configurations\n",
    "\n",
    "    The following code generates 1000 random hyperparameter configurations for the models to be trained in subsequent steps. This approach provides a broad exploration of the hyperparameter space.\n",
    "\n",
    "# Considerations for Customization\n",
    "\n",
    "    Initial Exploration:\n",
    "    You can begin with a smaller number of random searches and evaluate the verification outcomes.\n",
    "    This allows for a more focused selection of hyperparameter configurations by narrowing down the hyperparameter space based on the observed performance.\n",
    "\n",
    "# Replicating the Experiment\n",
    "    \n",
    "    Note: To replicate our exact experiment, please run the generated random configurations available in the supplementary folder.\n",
    "    Recommendation for flexibility:\n",
    "    While our code provides a specific set of random configurations, we encourage researchers to experiment with varying levels of randomness to potentially discover optimized configurations for their specific datasets and models.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config files have been created and saved in the Config files folder\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "============= Code to create 1000 random configs ===================\n",
    "\"\"\"\n",
    "\n",
    "# Create a new folder for the config files\n",
    "Path = r\"...\\Supplementary_materials\"\n",
    "config_folder = Path(\"Config_Hypertuning_files_paper_experiment\")\n",
    "config_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Define the hyperparameter grid for random search\n",
    "param_grid = {\n",
    "    'hidden_size': [16, 32, 64, 128, 256],\n",
    "    'initial_forget_bias': [-3, -1, 0, 1, 3],\n",
    "    'output_dropout': [0, 0.2, 0.4],\n",
    "    'batch_size': [32, 64, 128, 256],\n",
    "    'learning_rate': [{0: lr_1, 10: lr_2, 25: lr_3} for lr_1 in [1e-3, 1e-2, 5e-2]\n",
    "                      for lr_2 in [5e-4, 1e-3, 5e-3] for lr_3 in [1e-4, 1e-3]],\n",
    "    'target_noise_std': [0, 0.01, 0.02, 0.05, 0.1],\n",
    "    'loss': ['NSE', 'RMSE'], # {1, 2}\n",
    "    'regularization': ['tie_frequencies', None], # {1, 0}\n",
    "    'seq_length': [{'1D': length_1, '1H': length_2} for length_1 in [146, 182, 365, 730, 1095]\n",
    "                   for length_2 in [168, 336, 504, 672, 1344, 2016, 4032, 6720, 8064, 8760]],\n",
    "}\n",
    "\n",
    "# Specify the number of random samples to generate\n",
    "n_sample = 1000\n",
    "\n",
    "# Create a sampler to generate random hyperparameters\n",
    "param_sampler = ParameterSampler(param_grid, n_iter=n_sample)\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "results = {}\n",
    "output_results = {}\n",
    "\n",
    "# Loop through each set of hyperparameters\n",
    "for i, params in enumerate(param_sampler):\n",
    "    try:\n",
    "        # Create a new configuration file with a unique name based on the current set of hyperparameters\n",
    "        config_file = config_folder / Path(f\"Config_Hypertuning_{i}.yml\")\n",
    "\n",
    "        # Load the original configuration file and create a copy\n",
    "        config = yaml.load(Path(\"config_mts_LSTM.yml\").read_text(), Loader=yaml.SafeLoader)\n",
    "        config_copy = config.copy()\n",
    "\n",
    "        # Update the copy with the current set of hyperparameters\n",
    "        config_copy.update(params)\n",
    "\n",
    "        # Write the updated configuration to the new file\n",
    "        config_file.write_text(yaml.dump(config_copy, default_flow_style=False))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for params {params}: {e}\")\n",
    "        continue  # continue to the next set of hyperparameters\n",
    "\n",
    "print(\"Config files have been created and saved in the Config files folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============= Code to Run multiple trainings in parallel by NeuralHydrology Python library ===================\n",
    "\"\"\"\n",
    "\n",
    "config_folder = Path(\"Config_Hypertuning_files_paper_experiment\")\n",
    "\n",
    "# Set the mode, directory, GPU IDs, and runs per GPU\n",
    "mode = \"train\"\n",
    "directory = config_folder\n",
    "gpu_ids = [0, 1]  # List of GPU IDs to use (We had 2 GPUs cluster with 7 CPUs)\n",
    "runs_per_gpu = 5  # Number of runs to start on a single GPU depending on the resources. We could not increase to more than 5.\n",
    "\n",
    "try:\n",
    "    # Call the schedule_runs function\n",
    "    schedule_runs(mode, directory, gpu_ids, runs_per_gpu)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during execution: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================== After hypertuning finished and we want to only read folders ===================\n",
    "                        Extracting Hyperparameters and validation results\n",
    "\"\"\"\n",
    "\n",
    "# Define the parent directory that contains the folders with config files\n",
    "parent_dir = r'...\\Supplementary_materials\\Hypertuning' \n",
    "# Since 1000 Randomly trained models are too much data, we could not upload them all but after you run hypertuning, can use the following code to extract results from your experiment.\n",
    "\n",
    "# Set the directory for the results\n",
    "results_dir = Path(r'...\\Supplementary_materials\\Results')\n",
    "\n",
    "# Define the list of parameters to extract from the config files\n",
    "params = {\n",
    "    'hidden_size',\n",
    "    'initial_forget_bias',\n",
    "    'output_dropout',\n",
    "    'batch_size',\n",
    "    'learning_rate',\n",
    "    'target_noise_std',\n",
    "    'regularization',\n",
    "    'seq_length',\n",
    "    'loss',\n",
    "    'seed'\n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "hyperparameters_list = []\n",
    "\n",
    "# Iterate over the folders in the parent directory\n",
    "for folder_name in os.listdir(parent_dir):\n",
    "    # Create the path to the folder\n",
    "    folder_path = os.path.join(parent_dir, folder_name)\n",
    "    # Check if the path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Create an empty dictionary to store the hyperparameters for this folder\n",
    "        hyperparameters = {}\n",
    "        # Read the config file for this folder\n",
    "        try:\n",
    "            config_path = os.path.join(folder_path, \"config.yml\")\n",
    "            with open(config_path, \"r\") as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            # Extract the relevant hyperparameters from the config file\n",
    "            for param in params:\n",
    "                if param in config:\n",
    "                    if param == 'learning_rate':\n",
    "                        # Extract the individual learning rate values and add them as separate columns\n",
    "                        lr_dict = config[param]\n",
    "                        hyperparameters[\"Lr0\"] = lr_dict.get(0, None)\n",
    "                        hyperparameters[\"Lr10\"] = lr_dict.get(10, None)\n",
    "                        hyperparameters[\"Lr25\"] = lr_dict.get(25, None)\n",
    "                    elif param == 'seq_length':\n",
    "                        # Extract the individual sequence length values and add them as separate columns\n",
    "                        seq_dict = config[param]\n",
    "                        hyperparameters[\"Seq_1D\"] = seq_dict.get('1D', None)\n",
    "                        hyperparameters[\"Seq_1H\"] = seq_dict.get('1H', None)\n",
    "                    else:\n",
    "                        # Add the parameter value to the dictionary\n",
    "                        hyperparameters[param] = config[param]\n",
    "            # Add the folder name as a new column in the dictionary\n",
    "            hyperparameters[\"Model\"] = folder_name\n",
    "            # Append the dictionary to the list of results\n",
    "            hyperparameters_list.append(hyperparameters)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for params {folder_name}: {e}\")\n",
    "            continue  # continue to the next set of hyperparameters\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df_H = pd.DataFrame(hyperparameters_list)\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "df_V = pd.DataFrame()\n",
    "\n",
    "# Iterate through all the subfolders in the parent directory\n",
    "for folder in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(\"Processing folder:\", folder_path)\n",
    "        \n",
    "        # Navigate to the validation_results.p file\n",
    "        validation_path = os.path.join(folder_path, \"validation\", \"model_epoch050\", \"validation_results.p\")\n",
    "        try:\n",
    "            results = {}\n",
    "            output_results = {}\n",
    "            # Load the validation results\n",
    "            with open(validation_path, \"rb\") as f:\n",
    "                results = pickle.load(f)\n",
    "\n",
    "                # Store the results in the result dictionary with the params as the key\n",
    "                output_results[folder] = results  \n",
    "\n",
    "                # Loop through each set of hyperparameters\n",
    "                for params, metrics in output_results.items():\n",
    "                    # Loop through each basin and frequency\n",
    "                    for basin, freq_metrics in metrics.items():\n",
    "                        for freq, metric_values in freq_metrics.items():\n",
    "                            # Ignore the xr key and extract the other metrics\n",
    "                            metrics_dict = {k:v for k,v in metric_values.items() if k != 'xr'}\n",
    "                            \n",
    "                            # Append the metrics and hyperparameters to the dataframe\n",
    "                            row_dict = {'basin': basin, 'freq': freq, 'Model': params, **metrics_dict}\n",
    "                            df_V = pd.concat([df_V, pd.DataFrame([row_dict])], ignore_index=True)\n",
    "#                            df_V = df_V.append(row_dict, ignore_index=True)\n",
    "                        \n",
    "                # Delete the results object from memory to free up space\n",
    "                del results\n",
    "                del output_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for params {folder}: {e}\")\n",
    "            continue  # continue to the next set of hyperparameters\n",
    "\n",
    "# Merge columns with the same name prefix, keeping non-NaN values\n",
    "df_new = df_V.groupby(df_V.columns.str.replace('_1H|_1D', '', regex=True), axis=1).apply(lambda x: x.ffill(axis=1).iloc[:, -1]).astype(str)\n",
    "\n",
    "# Rename the columns to remove the '_1H' and '_1D' suffixes\n",
    "df_new.columns = df_new.columns.astype(str).str.rstrip('_1H').str.rstrip('_1D')\n",
    "\n",
    "# Merge the two DataFrames based on the \"folder_name\" column\n",
    "df_merged = pd.merge(df_H, df_new, on=\"Model\")\n",
    "\n",
    "df_merged['Model'] = df_merged['Model'].str.replace(\"Hypertuning_URA40Basins_\", \"\").str.replace(\"_\", \"\")\n",
    "\n",
    "column_order = ['Seq_1D', 'Seq_1H', 'batch_size', 'target_noise_std', 'Lr0', 'Lr10', 'Lr25', 'loss', 'hidden_size',\n",
    "                'output_dropout', 'initial_forget_bias', 'regularization', 'seed', 'Model', 'basin', 'freq', \n",
    "                'streamflowmean_NSE', 'levelmean_NSE', 'streamflowinst_NSE', 'levelinst_NSE',\n",
    "                'streamflowmean_KGE', 'levelmean_KGE', 'streamflowinst_KGE', 'levelinst_KGE']\n",
    "\n",
    "# Define the mapping from old names to new names\n",
    "column_mapping = {\n",
    "    'streamflowmean_NSE': 'SFmean_NSE',\n",
    "    'levelmean_NSE': 'WLmean_NSE',\n",
    "    'streamflowinst_NSE': 'SFinst_NSE',\n",
    "    'levelinst_NSE': 'WLinst_NSE',\n",
    "    'streamflowmean_KGE': 'SFmean_KGE',\n",
    "    'levelmean_KGE': 'WLmean_KGE',\n",
    "    'streamflowinst_KGE': 'SFinst_KGE',\n",
    "    'levelinst_KGE': 'WLinst_KGE'\n",
    "}\n",
    "\n",
    "df_merged = df_merged[column_order].rename(columns=column_mapping)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "df_merged.to_csv(results_dir /\"merged_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================== Removing outliers ===================\n",
    "We manually removed configurations having overall average performance metrics less than 0.5 from the post-Random Search DATASET (including 24 Configs)\n",
    "\"\"\"\n",
    "\n",
    "# List of basin names to remove\n",
    "models_to_remove = [\n",
    "    '105042308',\n",
    "    '908004510',\n",
    "    '1008124856',\n",
    "    '1108220501',\n",
    "    '1408071538',\n",
    "    '1708101122',\n",
    "    '1908031551',\n",
    "    '2008175336',\n",
    "    '2108085859',\n",
    "    '2408170627',\n",
    "    '2508212427',\n",
    "    '2607001222',\n",
    "    '2608143652',\n",
    "    '2608163243',\n",
    "    '2608193453',\n",
    "    '2704192907',\n",
    "    '2708194303',\n",
    "    '2708203837',\n",
    "    '2807141344',\n",
    "    '2904210252',\n",
    "    '3004145131',\n",
    "    '3007100701',\n",
    "    '3007141119',\n",
    "    '3107202900'\n",
    "] # These are models that had average metrics on all URA basins < 0.5\n",
    "\n",
    "# Filter the DataFrame to keep rows where the \"basin\" column is NOT in the specified list\n",
    "filtered_df = df_merged[~df_merged['Model'].isin(models_to_remove)]\n",
    "\n",
    "# List of basin names to remove (The ones that do not have verification data)\n",
    "basins_to_remove = [\n",
    "    'Abetxuko', 'Alegria', 'Araxes', 'Areta', 'Eibar',\n",
    "    'Etura', 'Gatika', 'Jaizubia', 'Larrainazubi', 'Markina',\n",
    "    'Ozaeta', 'Arenao', 'SanPrudentzio', 'Ibaieder', 'Sodupe'\n",
    "] # These are basins that we decided to remove from verification checkup due to data deficiencies (only 25 out of 40 basins where considered to decide on the best configuration post-Random Search)\n",
    "\n",
    "# Filter the DataFrame to keep rows where the \"basin\" column is NOT in the specified list\n",
    "filtered_df = filtered_df[~filtered_df['basin'].isin(basins_to_remove)]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_df.to_csv(os.path.join(results_dir, \"_merged_results_DeepCleaned_All.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================== To make SHPsT outcome, regionally out of basin scale ===================\n",
    "\"\"\"\n",
    "\n",
    "input_file_path = r'...\\Supplementary_materials\\Results\\merged_results_DeepCleaned_All.csv'\n",
    "data = pd.read_csv(input_file_path)\n",
    "grouped_data = data.groupby(['Model', 'freq']).mean().reset_index()\n",
    "\n",
    "column_order = ['Seq_1D', 'Seq_1H', 'batch_size', 'target_noise_std', 'Lr0', 'Lr10', 'Lr25', 'loss', 'hidden_size',\n",
    "                'output_dropout', 'initial_forget_bias', 'regularization', 'seed', 'Model', 'freq', \n",
    "                'SFmean_NSE', 'WLmean_NSE', 'SFinst_NSE', 'WLinst_NSE', 'SFmean_KGE', 'WLmean_KGE', 'SFinst_KGE', 'WLinst_KGE']\n",
    "\n",
    "grouped_data = grouped_data[column_order]\n",
    "\n",
    "output_file_path = r'...\\Supplementary_materials\\Results\\URA_merged_results_DeepCleaned_All.csv'\n",
    "grouped_data.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best-performing LSTM network (ERO) regarding their overall regional perofrmance NSE and KGE metrics\n",
    "## Choose the 10 best-performing LSTM networks (Top 10) regarding their overall regional perofrmance NSE and KGE metrics\n",
    "## Choose the best-performing LSTM network in each catchment (Catchment-Wise) regarding their perofrmance NSE and KGE metrics\n",
    "\n",
    "# The first three methods, use a sorted average metrics for URA_merged_results_DeepCleaned_All.csv\n",
    "\n",
    "## Choose the best-performing LSTM network (K-means) regarding both their catchment-scale and overall regional perofrmance NSE and KGE metrics\n",
    "\n",
    "# The last method uses the following codes to find the K-means configs.\n",
    "\n",
    "## Update final configurations and generate 10 configs for each network regarding 10 different random seeds to be retrained and tested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hosseinifh\\AppData\\Local\\anaconda3\\envs\\neuralhydrology\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Statistics:\n",
      "          SFmean_NSE  WLmean_NSE  SFinst_NSE  WLinst_NSE  SFmean_KGE  \\\n",
      "Cluster                                                               \n",
      "1          0.770800    0.842090    0.772263    0.842590    0.785530   \n",
      "2          0.773192    0.861862    0.774181    0.862168    0.788697   \n",
      "3          0.805766    0.843301    0.806668    0.843453    0.795598   \n",
      "4          0.772203    0.840377    0.773089    0.840627    0.778900   \n",
      "5          0.781588    0.837859    0.782797    0.838481    0.781284   \n",
      "6          0.769630    0.843648    0.770546    0.844040    0.777865   \n",
      "7          0.775609    0.856485    0.777152    0.856956    0.792956   \n",
      "8          0.777554    0.851210    0.778333    0.851296    0.780364   \n",
      "9          0.805486    0.860508    0.806479    0.860911    0.798656   \n",
      "10         0.760954    0.836313    0.761869    0.836729    0.771569   \n",
      "11         0.775454    0.843892    0.776251    0.844299    0.779419   \n",
      "12         0.802569    0.849768    0.803961    0.850228    0.794321   \n",
      "13         0.758247    0.841566    0.760002    0.842228    0.778904   \n",
      "14         0.804218    0.890661    0.805557    0.890924    0.790224   \n",
      "15         0.762766    0.834580    0.763732    0.834906    0.772059   \n",
      "16         0.816029    0.865590    0.817270    0.866043    0.800758   \n",
      "17         0.770877    0.860537    0.771680    0.860647    0.774457   \n",
      "18         0.764810    0.850630    0.765812    0.851291    0.787959   \n",
      "19         0.779820    0.859578    0.780885    0.859686    0.793014   \n",
      "20         0.779274    0.817548    0.780544    0.817940    0.775154   \n",
      "21         0.825866    0.857040    0.826922    0.857546    0.808303   \n",
      "22         0.771693    0.860044    0.772858    0.860421    0.786873   \n",
      "23         0.774539    0.844811    0.775308    0.845047    0.779517   \n",
      "24         0.812409    0.853619    0.814017    0.854132    0.798823   \n",
      "25         0.765580    0.844127    0.766744    0.844340    0.772237   \n",
      "\n",
      "         WLmean_KGE  SFinst_KGE  WLinst_KGE  \n",
      "Cluster                                      \n",
      "1          0.878522    0.786005    0.878628  \n",
      "2          0.884923    0.789507    0.885146  \n",
      "3          0.876438    0.796052    0.876388  \n",
      "4          0.869623    0.779465    0.869722  \n",
      "5          0.867639    0.781635    0.867634  \n",
      "6          0.870938    0.778517    0.871182  \n",
      "7          0.888191    0.794313    0.888436  \n",
      "8          0.875364    0.781126    0.875552  \n",
      "9          0.880659    0.799293    0.880743  \n",
      "10         0.867989    0.771960    0.868171  \n",
      "11         0.872101    0.780085    0.872405  \n",
      "12         0.877533    0.795307    0.877709  \n",
      "13         0.877436    0.779551    0.877599  \n",
      "14         0.871382    0.790625    0.871473  \n",
      "15         0.865268    0.772741    0.865279  \n",
      "16         0.884510    0.801688    0.884635  \n",
      "17         0.871829    0.775149    0.872023  \n",
      "18         0.885246    0.788724    0.885522  \n",
      "19         0.890726    0.793986    0.890778  \n",
      "20         0.856773    0.775739    0.856822  \n",
      "21         0.885157    0.808900    0.885284  \n",
      "22         0.884178    0.787797    0.884416  \n",
      "23         0.873791    0.779955    0.873798  \n",
      "24         0.877070    0.799851    0.877152  \n",
      "25         0.871630    0.773032    0.871725  \n",
      "Best Cluster:\n",
      "       Seq_1D  Seq_1H  batch_size  target_noise_std    Lr0    Lr10    Lr25  \\\n",
      "218     1095    2016          64              0.00  0.010  0.0050  0.0001   \n",
      "219     1095    2016          64              0.00  0.010  0.0050  0.0001   \n",
      "284     1095    2016         128              0.00  0.001  0.0050  0.0010   \n",
      "285     1095    2016         128              0.00  0.001  0.0050  0.0010   \n",
      "412     1095    2016          64              0.05  0.001  0.0050  0.0010   \n",
      "413     1095    2016          64              0.05  0.001  0.0050  0.0010   \n",
      "484     1095    2016         256              0.02  0.001  0.0010  0.0001   \n",
      "485     1095    2016         256              0.02  0.001  0.0010  0.0001   \n",
      "536     1095    2016         256              0.05  0.001  0.0010  0.0001   \n",
      "537     1095    2016         256              0.05  0.001  0.0010  0.0001   \n",
      "552     1095    2016          64              0.05  0.010  0.0010  0.0001   \n",
      "553     1095    2016          64              0.05  0.010  0.0010  0.0001   \n",
      "842     1095    2016         128              0.05  0.001  0.0050  0.0010   \n",
      "843     1095    2016         128              0.05  0.001  0.0050  0.0010   \n",
      "1166    1095    2016         128              0.05  0.001  0.0005  0.0001   \n",
      "1167    1095    2016         128              0.05  0.001  0.0005  0.0001   \n",
      "\n",
      "      loss  hidden_size  output_dropout  ...  freq  SFmean_NSE  WLmean_NSE  \\\n",
      "218      2           32             0.2  ...     2    0.827869    0.864564   \n",
      "219      2           32             0.2  ...     1    0.829635    0.868840   \n",
      "284      1           32             0.4  ...     2    0.817940    0.851869   \n",
      "285      1           32             0.4  ...     1    0.806577    0.843997   \n",
      "412      2           64             0.4  ...     2    0.831614    0.854930   \n",
      "413      2           64             0.4  ...     1    0.843156    0.868724   \n",
      "484      1           64             0.2  ...     2    0.820315    0.854328   \n",
      "485      1           64             0.2  ...     1    0.839104    0.872373   \n",
      "536      1           32             0.2  ...     2    0.826286    0.841094   \n",
      "537      1           32             0.2  ...     1    0.841015    0.867864   \n",
      "552      2           16             0.2  ...     2    0.816746    0.870663   \n",
      "553      2           16             0.2  ...     1    0.825940    0.860541   \n",
      "842      1           32             0.4  ...     2    0.830595    0.839346   \n",
      "843      1           32             0.4  ...     1    0.827533    0.848455   \n",
      "1166     1          128             0.4  ...     2    0.792379    0.842068   \n",
      "1167     1          128             0.4  ...     1    0.837146    0.862986   \n",
      "\n",
      "      SFinst_NSE  WLinst_NSE  SFmean_KGE  WLmean_KGE  SFinst_KGE  WLinst_KGE  \\\n",
      "218     0.829392    0.865234    0.812319    0.882442    0.813225    0.882369   \n",
      "219     0.828779    0.869017    0.789634    0.877059    0.787663    0.876813   \n",
      "284     0.820728    0.852441    0.797631    0.886589    0.797999    0.886604   \n",
      "285     0.808330    0.844717    0.775754    0.881796    0.777131    0.882163   \n",
      "412     0.832674    0.855265    0.826991    0.889593    0.827400    0.889558   \n",
      "413     0.843962    0.868885    0.821503    0.887080    0.822138    0.887693   \n",
      "484     0.822060    0.855119    0.823881    0.888224    0.824612    0.888457   \n",
      "485     0.839215    0.872239    0.812539    0.887233    0.813799    0.887510   \n",
      "536     0.829084    0.842030    0.825626    0.883758    0.827542    0.883660   \n",
      "537     0.841501    0.866363    0.801049    0.889331    0.801868    0.888834   \n",
      "552     0.818769    0.871151    0.799708    0.884250    0.799963    0.884267   \n",
      "553     0.826792    0.860918    0.788984    0.879825    0.790487    0.880285   \n",
      "842     0.832215    0.841560    0.827640    0.887249    0.827811    0.887102   \n",
      "843     0.826596    0.849258    0.798593    0.877502    0.797861    0.877963   \n",
      "1166    0.793706    0.843256    0.790561    0.877198    0.790590    0.877768   \n",
      "1167    0.836945    0.863278    0.840439    0.903385    0.842317    0.903500   \n",
      "\n",
      "      Cluster  \n",
      "218        21  \n",
      "219        21  \n",
      "284        21  \n",
      "285        21  \n",
      "412        21  \n",
      "413        21  \n",
      "484        21  \n",
      "485        21  \n",
      "536        21  \n",
      "537        21  \n",
      "552        21  \n",
      "553        21  \n",
      "842        21  \n",
      "843        21  \n",
      "1166       21  \n",
      "1167       21  \n",
      "\n",
      "[16 rows x 24 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-means Clustering to find the best-performing Configs in the validation DATASET\n",
    "\n",
    "\"\"\"\n",
    "This script performs hyperparameter clustering and statistical analysis\n",
    "        using KMeans, Seaborn Box Plot, and Pandas GroupBy.\n",
    "        This is just a regional check to plot a regional plot for paper\n",
    "        but the paper is based on basin metrics search not a regional average\n",
    "\"\"\"\n",
    "\n",
    "# Define the parent directory that contains the folders with config files\n",
    "parent_dir = Path(r'...\\Supplementary_materials\\Results')\n",
    "\n",
    "# Set the directory for the results\n",
    "results_dir = Path(r'...\\Supplementary_materials\\Results\\K_means')\n",
    "\n",
    "# Load the data into a pandas DataFrame with column names\n",
    "df = pd.read_csv(parent_dir / \"URA_merged_results_DeepCleaned_All.csv\", skiprows=[0],\n",
    "                 names=['Seq_1D', 'Seq_1H', 'batch_size', 'target_noise_std', 'Lr0', 'Lr10', 'Lr25', 'loss', 'hidden_size',\n",
    "                'output_dropout', 'initial_forget_bias', 'regularization', 'seed', 'Model', 'freq', \n",
    "                'SFmean_NSE', 'WLmean_NSE', 'SFinst_NSE', 'WLinst_NSE', 'SFmean_KGE', 'WLmean_KGE', 'SFinst_KGE', 'WLinst_KGE']).fillna(0)\n",
    "\n",
    "# Specify the number of clusters\n",
    "N_CLUSTERS = 25   \n",
    "\n",
    "# Instantiate KMeans object and fit to data\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS)\n",
    "kmeans.fit(df.drop(columns=['Model', 'seed', 'freq']).astype(float))\n",
    "\n",
    "# Assign cluster labels to each data point\n",
    "df['Cluster'] = kmeans.labels_ + 1\n",
    "\n",
    "# Group the data by cluster and calculate the mean KGE and NSE for each cluster\n",
    "cluster_stats = df.groupby('Cluster')[['SFmean_NSE', 'WLmean_NSE', 'SFinst_NSE', 'WLinst_NSE',\n",
    "                       'SFmean_KGE', 'WLmean_KGE', 'SFinst_KGE', 'WLinst_KGE']].mean()\n",
    "\n",
    "# Print the cluster statistics\n",
    "print(\"Cluster Statistics:\\n\", cluster_stats)\n",
    "\n",
    "# Create a boxplot of the KGE values for each cluster\n",
    "sns.boxplot(x='Cluster', y='SFmean_KGE', data=df)\n",
    "\n",
    "# Find the label of the cluster with the highest metrics\n",
    "best_cluster_label = cluster_stats['SFmean_KGE'].idxmax()\n",
    "\n",
    "# Select the rows corresponding to the best cluster\n",
    "best_cluster_df = df[df['Cluster'] == best_cluster_label]\n",
    "\n",
    "# Print the DataFrame containing the best cluster\n",
    "print(\"Best Cluster:\\n\", best_cluster_df)\n",
    "\n",
    "# Save the best cluster DataFrame to a CSV file\n",
    "best_cluster_df.to_csv(results_dir / 'best_cluster_reg.csv', index=False)\n",
    "\n",
    "# Save the DataFrame containing the best clusters to a CSV file including the Model name\n",
    "df.to_csv(results_dir / 'clusters_reg.csv', index=False)\n",
    "\n",
    "# Get the current figure object\n",
    "fig = plt.gcf()\n",
    "\n",
    "# Save the figure as a high-quality TIFF file\n",
    "fig.savefig(results_dir / 'Clusters_reg.tiff', dpi=300, format='tiff')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters_configuration_selected.csv in the Supplementary_materials is the final file including all 37 optimized regional configurations from the four different approaches.\n",
    "1. the ERO netdowk\n",
    "2. 10 Top regional Configs\n",
    "3. K-means regional selected Configs\n",
    "4. 23 Catchment-wise Configs\n",
    "\n",
    "Some of them are the same between different methods and all in all we had 37 distinct configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated configs have been saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Updating Configs for best performing HPs after 1000 Random Searches\n",
    "This code generates 370 configs that we will train them all (10 random seeds for every network)\n",
    "\"\"\"\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_directory = Path(r'...\\Supplementary_materials\\Results')\n",
    "original_config_directory = Path(r'...\\Supplementary_materials')\n",
    "\n",
    "# The CSV file path\n",
    "csv_path = csv_directory / \"Hyperparameters_configuration_selected.csv\"\n",
    "\n",
    "# Define the output configuration folder\n",
    "output_config_folder = Path(r'...\\Supplementary_materials\\post.RandomSearch_configs')\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "output_config_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load CSV data\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Read the original config\n",
    "original_config = yaml.load((original_config_directory / \"config_mts_LSTM.yml\").read_text(), Loader=yaml.SafeLoader)\n",
    "\n",
    "# Seeds to use\n",
    "seeds = [893856, 202981, 970216, 723952, 931334, 846266, 339685, 64410, 105209, 370654]\n",
    "\n",
    "# Iterate through rows of the CSV and update specific sections in the config\n",
    "for index, row in csv_data.iterrows():\n",
    "    for seed in seeds:\n",
    "        # Create a new config based on the original config\n",
    "        updated_config = original_config.copy()\n",
    "        \n",
    "        # Update seed value\n",
    "        updated_config['seed'] = seed\n",
    "\n",
    "        # Update specific sections with values from the CSV row\n",
    "        updated_config['seq_length'] = {\n",
    "            '1D': row['Seq_1D'],\n",
    "            '1H': row['Seq_1H']\n",
    "        }\n",
    "        updated_config['batch_size'] = row['batch_size']\n",
    "        updated_config['target_noise_std'] = row['target_noise_std']\n",
    "        updated_config['learning_rate'] = {\n",
    "            0: row['Lr0'],\n",
    "            10: row['Lr10'],\n",
    "            25: row['Lr25']\n",
    "        }\n",
    "        updated_config['loss'] = row['loss']\n",
    "        updated_config['hidden_size'] = row['hidden_size']\n",
    "        updated_config['output_dropout'] = row['output_dropout']\n",
    "        updated_config['initial_forget_bias'] = row['initial_forget_bias']\n",
    "        updated_config['regularization'] = [row['regularization']]\n",
    "        updated_config['run_dir'] = f'runs/train_test/{row[\"name\"]}'\n",
    "        updated_config['experiment_name'] = row['name']\n",
    "\n",
    "        # Generate the model name based on the \"model\" column\n",
    "        model_name = f\"{row['name']}_seed_{seed}\"\n",
    "\n",
    "        # Save the updated config to a new YAML file\n",
    "        output_config_file = output_config_folder / f'{model_name}_config.yml'\n",
    "        with open(output_config_file, 'w') as out_config_file:\n",
    "            yaml.dump(updated_config, out_config_file, default_flow_style=False)\n",
    "\n",
    "print(\"Updated configs have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============= Code to Run multiple retrainings in parallel for final hyper-tuned networks by NeuralHydrology Python library ===================\n",
    "\"\"\"\n",
    "\n",
    "config_folder = Path(\"post.RandomSearch_configs\")\n",
    "\n",
    "# Set the mode, directory, GPU IDs, and runs per GPU\n",
    "mode = \"train\"\n",
    "directory = config_folder\n",
    "gpu_ids = [0, 1]  # List of GPU IDs to use (We had 2 GPUs cluster with 7 CPUs)\n",
    "runs_per_gpu = 5  # Number of runs to start on a single GPU depending on the resources. We could not increase to more than 5.\n",
    "\n",
    "try:\n",
    "    # Call the schedule_runs function\n",
    "    schedule_runs(mode, directory, gpu_ids, runs_per_gpu)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during execution: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============= To load all Training Folders for All networks and Test them on test set =============\n",
    "                We will have 370 final fully trained/tested models networks\n",
    "\"\"\"\n",
    "\n",
    "# Define the parent directory that contains the folders with config files\n",
    "parent_dir_cluster = r\"...\\Supplementary_materials\\trained_models\\ERO_Overfitting_Checked\"                      # for ERO - Overfitting checked manually after retraining by Python Tensorboard\n",
    "# parent_dir_cluster = r\"...\\Supplementary_materials\\trained_models\\Top10Configs_Overfitting_Checked\"           # for Top10Configs Ensemble - Overfitting checked manually after retraining by Python Tensorboard\n",
    "# parent_dir_cluster = r\"...\\Supplementary_materials\\trained_models\\K_means_Configs_Overfitting_Checked\"        # for K_means_configured Ensemble - Overfitting checked manually after retraining by Python Tensorboard\n",
    "# parent_dir_cluster = r\"...\\Supplementary_materials\\trained_models\\Catchment_Wise_Configs\"                     # for Catchment-Wise Configs Ensemble - All mdoels after 50 epochs were taken\n",
    "\n",
    "for folder_name in os.listdir(parent_dir_cluster):\n",
    "    # Create the path to the folder\n",
    "    folder_path = os.path.join(parent_dir_cluster, folder_name)\n",
    "    # Check if the path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        try:\n",
    "            run_config_path = os.path.join(folder_path, \"config.yml\")\n",
    "\n",
    "            # Load the config.yml file\n",
    "            with open(run_config_path, 'r') as file:\n",
    "                run_config = yaml.safe_load(file)\n",
    "\n",
    "            # Create an instance of the Config class\n",
    "            cfg = Config(run_config)\n",
    "\n",
    "            # create a tester instance and start evaluation\n",
    "            tester = get_tester(cfg=cfg, run_dir=Path(folder_path), period=\"test\", init_model=True)\n",
    "            results = tester.evaluate(save_results=True, metrics=cfg.metrics)\n",
    "\n",
    "            results.keys()\n",
    "\n",
    "            print(\"Folder name:\", folder_name)\n",
    "            print(\"Config file path:\", run_config_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for folder {folder_name}: {e}\")\n",
    "            continue  # continue to the next folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================== After All Tests finished, we want to make output results file ===================\n",
    "            Extracting Hyperparameters and test metrics for RO and ERO trained/tested models\n",
    "\"\"\"\n",
    "\n",
    "parent_dir = r\"...\\Supplementary_materials\\trained_models\\ERO_Overfitting_Checked\"                      # for ERO\n",
    "# parent_dir = r\"...\\Supplementary_materials\\trained_models\\Top10Configs_Overfitting_Checked\"           # for Top10Configs Ensemble\n",
    "# parent_dir = r\"...\\Supplementary_materials\\trained_models\\K_means_Configs_Overfitting_Checked\"     # for K_means_configured Ensemble\n",
    "\n",
    "# Set the directory for the results\n",
    "results_dir = Path(r'...\\Supplementary_materials\\Results\\test')\n",
    "\n",
    "# Define the list of parameters to extract from the config files\n",
    "params = {\n",
    "    'hidden_size',\n",
    "    'initial_forget_bias',\n",
    "    'output_dropout',\n",
    "    'batch_size',\n",
    "    'learning_rate',\n",
    "    'target_noise_std',\n",
    "    'regularization',\n",
    "    'seq_length',\n",
    "    'loss',\n",
    "    'seed'\n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "hyperparameters_list = []\n",
    "\n",
    "# Iterate over the folders in the parent directory\n",
    "for folder_name in os.listdir(parent_dir):\n",
    "    # Create the path to the folder\n",
    "    folder_path = os.path.join(parent_dir, folder_name)\n",
    "    # Check if the path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Create an empty dictionary to store the hyperparameters for this folder\n",
    "        hyperparameters = {}\n",
    "        # Read the config file for this folder\n",
    "        try:\n",
    "            config_path = os.path.join(folder_path, \"config.yml\")\n",
    "            with open(config_path, \"r\") as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            # Extract the relevant hyperparameters from the config file\n",
    "            for param in params:\n",
    "                if param in config:\n",
    "                    if param == 'learning_rate':\n",
    "                        # Extract the individual learning rate values and add them as separate columns\n",
    "                        lr_dict = config[param]\n",
    "                        hyperparameters[\"Lr0\"] = lr_dict.get(0, None)\n",
    "                        hyperparameters[\"Lr10\"] = lr_dict.get(10, None)\n",
    "                        hyperparameters[\"Lr25\"] = lr_dict.get(25, None)\n",
    "                    elif param == 'seq_length':\n",
    "                        # Extract the individual sequence length values and add them as separate columns\n",
    "                        seq_dict = config[param]\n",
    "                        hyperparameters[\"Seq_1D\"] = seq_dict.get('1D', None)\n",
    "                        hyperparameters[\"Seq_1H\"] = seq_dict.get('1H', None)\n",
    "                    else:\n",
    "                        # Add the parameter value to the dictionary\n",
    "                        hyperparameters[param] = config[param]\n",
    "            # Add the folder name as a new column in the dictionary\n",
    "            hyperparameters[\"Model\"] = folder_name\n",
    "            # Append the dictionary to the list of results\n",
    "            hyperparameters_list.append(hyperparameters)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for params {folder_name}: {e}\")\n",
    "            continue  # continue to the next set of hyperparameters\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df_H = pd.DataFrame(hyperparameters_list)\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "df_V = pd.DataFrame()\n",
    "\n",
    "# Iterate through all the subfolders in the parent directory\n",
    "for folder in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(\"Processing folder:\", folder_path)\n",
    "        \n",
    "        # Navigate to the test_results.p file\n",
    "        test_folder = os.path.join(folder_path, \"test\")\n",
    "        for folder_test in os.listdir(test_folder):\n",
    "            test_path = os.path.join(folder_path, \"test\", folder_test, \"test_results.p\")\n",
    "        try:\n",
    "            results = {}\n",
    "            output_results = {}\n",
    "            # Load the validation results\n",
    "            with open(test_path, \"rb\") as f:\n",
    "                # results = pickle.load(f)\n",
    "                results = pd.read_pickle(f)\n",
    "                # Store the results in the result dictionary with the params as the key\n",
    "                output_results[folder] = results  \n",
    "\n",
    "                # Loop through each set of hyperparameters\n",
    "                for params, metrics in output_results.items():\n",
    "                    # Loop through each basin and frequency\n",
    "                    for basin, freq_metrics in metrics.items():\n",
    "                        for freq, metric_values in freq_metrics.items():\n",
    "                            # Ignore the xr key and extract the other metrics\n",
    "                            metrics_dict = {k:v for k,v in metric_values.items() if k != 'xr'}\n",
    "                            \n",
    "                            # Append the metrics and hyperparameters to the dataframe\n",
    "                            row_dict = {'basin': basin, 'freq': freq, 'Model': params, **metrics_dict}\n",
    "                            df_V = pd.concat([df_V, pd.DataFrame([row_dict])], ignore_index=True)\n",
    "                        \n",
    "                # Delete the results object from memory to free up space\n",
    "                del results\n",
    "                del output_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for params {folder}: {e}\")\n",
    "            continue  # continue to the next set of hyperparameters\n",
    "\n",
    "# Rename the columns to remove the '_1H' and '_1D' suffixes\n",
    "df_V.columns = df_V.columns.astype(str).str.rstrip('_1H').str.rstrip('_1D')\n",
    "\n",
    "# Merge columns with the same name prefix, keeping non-NaN values\n",
    "df_new = df_V.groupby(df_V.columns.str.replace('_1H|_1D', '', regex=True), axis=1).apply(lambda x: x.ffill(axis=1).iloc[:, -1]).astype(str)\n",
    "\n",
    "# Merge the two DataFrames based on the \"folder_name\" column\n",
    "df_merged = pd.merge(df_H, df_new, on=\"Model\")\n",
    "\n",
    "column_order = ['Seq_1D', 'Seq_1H', 'batch_size', 'target_noise_std', 'Lr0', 'Lr10', 'Lr25', 'loss', 'hidden_size',\n",
    "                'output_dropout', 'initial_forget_bias', 'regularization', 'seed', 'Model', 'basin', 'freq', \n",
    "                'streamflowmean_NSE',       'levelmean_NSE',        'streamflowinst_NSE',       'levelinst_NSE', \n",
    "                'streamflowmean_KGE',       'levelmean_KGE',        'streamflowinst_KGE',       'levelinst_KGE', \n",
    "                'streamflowmean_MSE',       'levelmean_MSE',        'streamflowinst_MSE',       'levelinst_MSE',\n",
    "                'streamflowmean_RMSE',      'levelmean_RMSE',       'streamflowinst_RMSE',      'levelinst_RMSE', \n",
    "                'streamflowmean_Alpha-NSE', 'levelmean_Alpha-NSE',  'streamflowinst_Alpha-NSE', 'levelinst_Alpha-NSE', \n",
    "                'streamflowmean_Beta-NSE',  'levelmean_Beta-NSE',   'streamflowinst_Beta-NSE',  'levelinst_Beta-NSE',\n",
    "                'streamflowmean_Pearson-r', 'levelmean_Pearson-r',  'streamflowinst_Pearson-r', 'levelinst_Pearson-r', \n",
    "                'streamflowmean_Beta-KGE',  'levelmean_Beta-KGE',   'streamflowinst_Beta-KGE',  'levelinst_Beta-KGE', \n",
    "                'streamflowmean_FHV',       'levelmean_FHV',        'streamflowinst_FHV',       'levelinst_FHV',\n",
    "                'streamflowmean_FMS',       'levelmean_FMS',        'streamflowinst_FMS',       'levelinst_FMS', \n",
    "                'streamflowmean_FLV',       'levelmean_FLV',        'streamflowinst_FLV',       'levelinst_FLV', \n",
    "                'streamflowmean_Peak-Timing','levelmean_Peak-Timing', 'streamflowinst_Peak-Timing', 'levelinst_Peak-Timing',\n",
    "                'streamflowmean_Peak-MAPE', 'levelmean_Peak-MAPE',  'streamflowinst_Peak-MAPE', 'levelinst_Peak-MAPE',\n",
    "                'streamflowmean_Missed-Peaks', 'levelmean_Missed-Peaks',  'streamflowinst_Missed-Peaks', 'levelinst_Missed-Peaks']\n",
    "\n",
    "# Define the mapping from old names to new names\n",
    "column_mapping = {\n",
    "    'streamflowmean_NSE': 'SFmean_NSE',\n",
    "    'levelmean_NSE': 'WLmean_NSE',\n",
    "    'streamflowinst_NSE': 'SFinst_NSE',\n",
    "    'levelinst_NSE': 'WLinst_NSE',\n",
    "    'streamflowmean_KGE': 'SFmean_KGE',\n",
    "    'levelmean_KGE': 'WLmean_KGE',\n",
    "    'streamflowinst_KGE': 'SFinst_KGE',\n",
    "    'levelinst_KGE': 'WLinst_KGE',\n",
    "    'streamflowmean_MSE': 'SFmean_MSE',\n",
    "    'levelmean_MSE': 'WLmean_MSE',\n",
    "    'streamflowinst_MSE': 'SFinst_MSE',\n",
    "    'levelinst_MSE': 'WLinst_MSE',\n",
    "    'streamflowmean_RMSE': 'SFmean_RMSE',\n",
    "    'levelmean_RMSE': 'WLmean_RMSE',\n",
    "    'streamflowinst_RMSE': 'SFinst_RMSE',\n",
    "    'levelinst_RMSE': 'WLinst_RMSE',\n",
    "    'streamflowmean_Alpha-NSE': 'SFmean_Alpha-NSE',\n",
    "    'levelmean_Alpha-NSE': 'WLmean_Alpha-NSE',\n",
    "    'streamflowinst_Alpha-NSE': 'SFinst_Alpha-NSE',\n",
    "    'levelinst_Alpha-NSE': 'WLinst_Alpha-NSE',\n",
    "    'streamflowmean_Beta-NSE': 'SFmean_Beta-NSE',\n",
    "    'levelmean_Beta-NSE': 'WLmean_Beta-NSE',\n",
    "    'streamflowinst_Beta-NSE': 'SFinst_Beta-NSE',\n",
    "    'levelinst_Beta-NSE': 'WLinst_Beta-NSE',\n",
    "    'streamflowmean_Pearson-r': 'SFmean_Pearson-r',\n",
    "    'levelmean_Pearson-r': 'WLmean_Pearson-r',\n",
    "    'streamflowinst_Pearson-r': 'SFinst_Pearson-r',\n",
    "    'levelinst_Pearson-r': 'WLinst_Pearson-r',\n",
    "    'streamflowmean_Beta-KGE': 'SFmean_Beta-KGE',\n",
    "    'levelmean_Beta-KGE': 'WLmean_Beta-KGE',\n",
    "    'streamflowinst_Beta-KGE': 'SFinst_Beta-KGE',\n",
    "    'levelinst_Beta-KGE': 'WLinst_Beta-KGE',\n",
    "    'streamflowmean_FHV': 'SFmean_FHV',\n",
    "    'levelmean_FHV': 'WLmean_FHV',\n",
    "    'streamflowinst_FHV': 'SFinst_FHV',\n",
    "    'levelinst_FHV': 'WLinst_FHV',\n",
    "    'streamflowmean_FMS': 'SFmean_FMS',\n",
    "    'levelmean_FMS': 'WLmean_FMS',\n",
    "    'streamflowinst_FMS': 'SFinst_FMS',\n",
    "    'levelinst_FMS': 'WLinst_FMS',\n",
    "    'streamflowmean_FLV': 'SFmean_FLV',\n",
    "    'levelmean_FLV': 'WLmean_FLV',\n",
    "    'streamflowinst_FLV': 'SFinst_FLV',\n",
    "    'levelinst_FLV': 'WLinst_FLV',\n",
    "    'streamflowmean_Peak-Timing': 'SFmean_Peak-Timing',\n",
    "    'levelmean_Peak-Timing': 'WLmean_Peak-Timing',\n",
    "    'streamflowinst_Peak-Timing': 'SFinst_Peak-Timing',\n",
    "    'levelinst_Peak-Timing': 'WLinst_Peak-Timing',\n",
    "    'streamflowmean_Peak-MAPE': 'SFmean_Peak-MAPE',\n",
    "    'levelmean_Peak-MAPE': 'WLmean_Peak-MAPE',\n",
    "    'streamflowinst_Peak-MAPE': 'SFinst_Peak-MAPE',\n",
    "    'levelinst_Peak-MAPE': 'WLinst_Peak-MAPE',\n",
    "    'streamflowmean_Missed-Peaks': 'SFmean_Missed-Peaks',\n",
    "    'levelmean_Missed-Peaks': 'WLmean_Missed-Peaks',\n",
    "    'streamflowinst_Missed-Peaks': 'SFinst_Missed-Peaks',\n",
    "    'levelinst_Missed-Peaks': 'WLinst_Missed-Peaks'\n",
    "}\n",
    "\n",
    "df_merged = df_merged[column_order].rename(columns=column_mapping)\n",
    "df_merged[\"Model\"] = df_merged[\"Model\"].str.replace(\"One_Fits_All_1000_\", \"\").str.replace(\"_\", \"\")\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "df_merged.to_csv(results_dir /\"ERO.metrics.csv\", index=False)\n",
    "# df_merged.to_csv(results_dir /\"Top10Configs.metrics.csv\", index=False)\n",
    "# df_merged.to_csv(results_dir /\"K_means.metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the results can be found on the other code in Supplementary_materials named: \"Master_EnsembleDeepLearningInRegionalHydrology\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('neuralhydrology')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "28551622292ccb4dcc86d22310aeda6925dc431b53c4ccf22ac904f319eed257"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
